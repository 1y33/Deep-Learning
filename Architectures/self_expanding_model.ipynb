{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchsummary\n",
    "import torch.nn.functional as F"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:01:14.269701600Z",
     "start_time": "2024-03-18T20:01:14.260694100Z"
    }
   },
   "id": "9861d0babcae96ce",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self,in_ch,out_ch,drop_out = True):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_ch,out_ch,3,1,1)\n",
    "        self.conv2 = nn.Conv2d(out_ch,out_ch,3,1,1)\n",
    "        self.BatchNorm1 = nn.BatchNorm2d(out_ch)\n",
    "        self.BatchNorm2 = nn.BatchNorm2d(out_ch)\n",
    "        \n",
    "        if drop_out:\n",
    "            self.drop_out = nn.Dropout(0.5, inplace = True)\n",
    "        else:\n",
    "            self.drop_out = nn.Identity()\n",
    "            \n",
    "        if in_ch != out_ch:\n",
    "            self.shortcut = nn.Conv2d(in_ch,out_ch,1)\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()\n",
    "    def forward(self,x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = self.BatchNorm1(out)\n",
    "        out = self.drop_out(out)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.BatchNorm2(out)\n",
    "        \n",
    "        x += self.shortcut(out)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def  __init__(self,in_ch,out_ch):\n",
    "        super().__init__()\n",
    "        self.in_ch = in_ch\n",
    "        self.out_ch = out_ch\n",
    "        self.res_ch = max(in_ch,out_ch) // 2\n",
    "        \n",
    "        \n",
    "        self.head = nn.Conv2d(self.in_ch,self.res_ch,1,bias=False)\n",
    "        self.tail = nn.Conv2d(self.res_ch,out_ch,1,bias=False)\n",
    "        \n",
    "        self.model = []\n",
    "        self.block = nn.Sequential(*self.model)\n",
    "        \n",
    "    def _append(self):\n",
    "        self.block.append(ResidualBlock(self.res_ch,self.res_ch))\n",
    "        self.block.append(nn.ReLU(inplace=True))\n",
    "        self.res_ch *= 2\n",
    "        self.block = nn.Sequential(*self.block)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.head(x)\n",
    "        x = self.block(x)\n",
    "        x = self.tail(x)\n",
    "        \n",
    "        return x\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:01:14.846774Z",
     "start_time": "2024-03-18T20:01:14.840254700Z"
    }
   },
   "id": "cc3853c2fb631980",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self,channels,classes):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.classes = classes\n",
    "        \n",
    "        # 256 x 256 x 3\n",
    "        # 128 x 128 x 64\n",
    "        # 64 x 64 x 128\n",
    "        # 32 x 32 x 256\n",
    "        # 16 x 16 x 512\n",
    "        # 8 x 8 x 1024 -> fully connected layers\n",
    "        \n",
    "        self.block_1 = Block(self.channels,64)\n",
    "        self.block_2 = Block(64,128)\n",
    "        self.block_3 = Block(128,256)\n",
    "        self.block_4 = Block(256,512)\n",
    "        self.block_5 = Block(512,1024)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = F.max_pool2d(self.block_1(x),2)\n",
    "        x = F.max_pool2d(self.block_2(x),2)\n",
    "        x = F.max_pool2d(self.block_3(x),2)\n",
    "        x = F.max_pool2d(self.block_4(x),2)\n",
    "        x = F.max_pool2d(self.block_5(x),2)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:01:15.138439400Z",
     "start_time": "2024-03-18T20:01:15.128673100Z"
    }
   },
   "id": "1489d3d514890ca9",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:01:15.794998400Z",
     "start_time": "2024-03-18T20:01:15.790991700Z"
    }
   },
   "id": "ceb0650dc65489d5",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046624 - params before _append\n",
      "7337888 - params after _append\n"
     ]
    }
   ],
   "source": [
    "random = CNNModel(3,10)\n",
    "total_params = sum(p.numel() for p in random.parameters())\n",
    "print(f\"{total_params} - params before _append\")\n",
    "random.block_5._append()\n",
    "random.block_4._append()\n",
    "random.block_3._append()\n",
    "random.block_2._append()\n",
    "random.block_1._append()\n",
    "\n",
    "total_params = sum(p.numel() for p in random.parameters())\n",
    "print(f\"{total_params} - params after _append\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:01:22.561784400Z",
     "start_time": "2024-03-18T20:01:22.514773Z"
    }
   },
   "id": "c5940c532c52af4c",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Block: 1-1                             [-1, 64, 256, 256]        --\n",
      "|    └─Conv2d: 2-1                       [-1, 32, 256, 256]        96\n",
      "|    └─Sequential: 2-2                   [-1, 32, 256, 256]        --\n",
      "|    |    └─ResidualBlock: 3-1           [-1, 32, 256, 256]        18,624\n",
      "|    |    └─ReLU: 3-2                    [-1, 32, 256, 256]        --\n",
      "|    └─Conv2d: 2-3                       [-1, 64, 256, 256]        2,048\n",
      "├─Block: 1-2                             [-1, 128, 128, 128]       --\n",
      "|    └─Conv2d: 2-4                       [-1, 64, 128, 128]        4,096\n",
      "|    └─Sequential: 2-5                   [-1, 64, 128, 128]        --\n",
      "|    |    └─ResidualBlock: 3-3           [-1, 64, 128, 128]        74,112\n",
      "|    |    └─ReLU: 3-4                    [-1, 64, 128, 128]        --\n",
      "|    └─Conv2d: 2-6                       [-1, 128, 128, 128]       8,192\n",
      "├─Block: 1-3                             [-1, 256, 64, 64]         --\n",
      "|    └─Conv2d: 2-7                       [-1, 128, 64, 64]         16,384\n",
      "|    └─Sequential: 2-8                   [-1, 128, 64, 64]         --\n",
      "|    |    └─ResidualBlock: 3-5           [-1, 128, 64, 64]         295,680\n",
      "|    |    └─ReLU: 3-6                    [-1, 128, 64, 64]         --\n",
      "|    └─Conv2d: 2-9                       [-1, 256, 64, 64]         32,768\n",
      "├─Block: 1-4                             [-1, 512, 32, 32]         --\n",
      "|    └─Conv2d: 2-10                      [-1, 256, 32, 32]         65,536\n",
      "|    └─Sequential: 2-11                  [-1, 256, 32, 32]         --\n",
      "|    |    └─ResidualBlock: 3-7           [-1, 256, 32, 32]         1,181,184\n",
      "|    |    └─ReLU: 3-8                    [-1, 256, 32, 32]         --\n",
      "|    └─Conv2d: 2-12                      [-1, 512, 32, 32]         131,072\n",
      "├─Block: 1-5                             [-1, 1024, 16, 16]        --\n",
      "|    └─Conv2d: 2-13                      [-1, 512, 16, 16]         262,144\n",
      "|    └─Sequential: 2-14                  [-1, 512, 16, 16]         --\n",
      "|    |    └─ResidualBlock: 3-9           [-1, 512, 16, 16]         4,721,664\n",
      "|    |    └─ReLU: 3-10                   [-1, 512, 16, 16]         --\n",
      "|    └─Conv2d: 2-15                      [-1, 1024, 16, 16]        524,288\n",
      "==========================================================================================\n",
      "Total params: 7,337,888\n",
      "Trainable params: 7,337,888\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 7.01\n",
      "==========================================================================================\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 217.00\n",
      "Params size (MB): 27.99\n",
      "Estimated Total Size (MB): 245.74\n",
      "==========================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": "==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\n├─Block: 1-1                             [-1, 64, 256, 256]        --\n|    └─Conv2d: 2-1                       [-1, 32, 256, 256]        96\n|    └─Sequential: 2-2                   [-1, 32, 256, 256]        --\n|    |    └─ResidualBlock: 3-1           [-1, 32, 256, 256]        18,624\n|    |    └─ReLU: 3-2                    [-1, 32, 256, 256]        --\n|    └─Conv2d: 2-3                       [-1, 64, 256, 256]        2,048\n├─Block: 1-2                             [-1, 128, 128, 128]       --\n|    └─Conv2d: 2-4                       [-1, 64, 128, 128]        4,096\n|    └─Sequential: 2-5                   [-1, 64, 128, 128]        --\n|    |    └─ResidualBlock: 3-3           [-1, 64, 128, 128]        74,112\n|    |    └─ReLU: 3-4                    [-1, 64, 128, 128]        --\n|    └─Conv2d: 2-6                       [-1, 128, 128, 128]       8,192\n├─Block: 1-3                             [-1, 256, 64, 64]         --\n|    └─Conv2d: 2-7                       [-1, 128, 64, 64]         16,384\n|    └─Sequential: 2-8                   [-1, 128, 64, 64]         --\n|    |    └─ResidualBlock: 3-5           [-1, 128, 64, 64]         295,680\n|    |    └─ReLU: 3-6                    [-1, 128, 64, 64]         --\n|    └─Conv2d: 2-9                       [-1, 256, 64, 64]         32,768\n├─Block: 1-4                             [-1, 512, 32, 32]         --\n|    └─Conv2d: 2-10                      [-1, 256, 32, 32]         65,536\n|    └─Sequential: 2-11                  [-1, 256, 32, 32]         --\n|    |    └─ResidualBlock: 3-7           [-1, 256, 32, 32]         1,181,184\n|    |    └─ReLU: 3-8                    [-1, 256, 32, 32]         --\n|    └─Conv2d: 2-12                      [-1, 512, 32, 32]         131,072\n├─Block: 1-5                             [-1, 1024, 16, 16]        --\n|    └─Conv2d: 2-13                      [-1, 512, 16, 16]         262,144\n|    └─Sequential: 2-14                  [-1, 512, 16, 16]         --\n|    |    └─ResidualBlock: 3-9           [-1, 512, 16, 16]         4,721,664\n|    |    └─ReLU: 3-10                   [-1, 512, 16, 16]         --\n|    └─Conv2d: 2-15                      [-1, 1024, 16, 16]        524,288\n==========================================================================================\nTotal params: 7,337,888\nTrainable params: 7,337,888\nNon-trainable params: 0\nTotal mult-adds (G): 7.01\n==========================================================================================\nInput size (MB): 0.75\nForward/backward pass size (MB): 217.00\nParams size (MB): 27.99\nEstimated Total Size (MB): 245.74\n=========================================================================================="
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchsummary.summary(random, input_data=(3,256,256))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T20:01:23.261745100Z",
     "start_time": "2024-03-18T20:01:22.878596700Z"
    }
   },
   "id": "a69ac8ec6d52be7",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1b71a2d2b7ab1ba5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
