{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import torchsummary\n",
    "from torch_snippets import *\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(36)\n",
    "torch.cuda.manual_seed(36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2028b0b90d56c19",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Hyper Params\n",
    "\n",
    "IMAGE_SIZE = 128\n",
    "LR = 1e-4\n",
    "BIAS = False\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "path_2_train = \"Pix2Pix/maps/train\"\n",
    "path_2_val = \"Pix2Pix/maps/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fcf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_numpy(img):\n",
    "    img = np.transpose(img, axes =(1,0,2))\n",
    "    plt.imshow(img,cmap=\"RdYlBu\")\n",
    "    plt.axis(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224931a8492992b4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import PIL.Image as Image\n",
    "\n",
    "x = Image.open(os.path.join(\"maps/maps/train/4.jpg\"))\n",
    "x = np.array(x)\n",
    "first_half = x[:,:600,:]\n",
    "second_half = x[:,600:,:]\n",
    "show_numpy(first_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df88c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_index = np.random.randint(0,1000)\n",
    "random_index = int(random_index)\n",
    "all_dataset = os.path.join(\"maps/maps/train/\",f\"{random_index}.jpg\")\n",
    "\n",
    "all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955ae8efd4ea5f4b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "class Image_Dataset(Dataset):\n",
    "    def __init__(self,path):\n",
    "        self.path_2_images = os.path.join(path) \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        ])\n",
    "        self.len = os.listdir(self.path_2_images)\n",
    "    def __len__(self):\n",
    "        return len(self.len)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        index += 1\n",
    "        full_image = os.path.join(self.path_2_images,f\"{index}.jpg\")\n",
    "        image = Image.open(full_image)\n",
    "        image = np.array(image)\n",
    "\n",
    "        label = self.transform(image[:,600:,:])\n",
    "        target = self.transform(image[:,:600,:])\n",
    "\n",
    "        return label,target,image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985d978172305911",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_ds = Image_Dataset(\"maps/maps/train/\")\n",
    "\n",
    "for x,y,z in data_ds:\n",
    "    print(x.shape,y.shape,z.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6183d3a53c0d0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ResConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(ResConv, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.conv_2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.bn_1 = nn.BatchNorm2d(out_ch)\n",
    "        self.bn_2 = nn.BatchNorm2d(out_ch)\n",
    "        if in_ch != out_ch:\n",
    "            self.res = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "        else:\n",
    "            self.res = nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residue = x\n",
    "        out = self.conv_1(x)\n",
    "        out = self.bn_1(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "\n",
    "        out = self.conv_2(out)\n",
    "        out = self.bn_2(out)\n",
    "        out = F.relu(out)\n",
    "\n",
    "        out += self.res(x)\n",
    "\n",
    "        return out, residue  # Return the residual connection\n",
    "\n",
    "\n",
    "class DownConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(DownConv, self).__init__()\n",
    "\n",
    "        self.res = ResConv(in_ch, out_ch)\n",
    "        self.downsample = nn.MaxPool2d(2)\n",
    "        self.conv = nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, residue = self.res(x)  # Get the output tensor and the residue\n",
    "        x = self.downsample(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return x, residue\n",
    "\n",
    "\n",
    "class UpConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, batch_norm_features):\n",
    "        super(UpConv, self).__init__()\n",
    "\n",
    "        self.res = ResConv(in_ch, in_ch)\n",
    "        self.upsample = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=4, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bn = nn.BatchNorm2d(batch_norm_features)\n",
    "\n",
    "    def forward(self, x, x_skip):\n",
    "        x, residue = self.res(x)  # Get the output tensor and the residue\n",
    "        x = self.upsample(x)\n",
    "\n",
    "        x = torch.cat([x, x_skip], dim=1)  # Concatenate with skip connection\n",
    "        x = self.relu(x)\n",
    "        x = self.bn(x)\n",
    "\n",
    "        return x, residue\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, in_ch_skip):\n",
    "        super(Attention, self).__init__()\n",
    "        self.in_ch_skip = in_ch_skip\n",
    "        self.in_ch_lower = in_ch_skip // 2\n",
    "\n",
    "        # Adjust the number of output channels of conv_x\n",
    "        self.conv_x = nn.Conv2d(self.in_ch_skip, self.in_ch_lower, kernel_size=1, stride=2)\n",
    "        self.conv_g = nn.Conv2d(self.in_ch_lower, self.in_ch_lower, kernel_size=1)\n",
    "        self.conv_1 = nn.Conv2d(self.in_ch_lower, 1, kernel_size=1)\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\")\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x_skip, x_lower):\n",
    "         x_skip_adjusted = self.conv_x(x_skip)\n",
    "         x_lower = self.conv_g(x_lower)\n",
    "\n",
    "         out = x_skip_adjusted + x_lower\n",
    "         out = self.relu(out)\n",
    "         out = self.conv_1(out)\n",
    "\n",
    "         out = torch.sigmoid(out)\n",
    "         out = self.upsample(out)\n",
    "\n",
    "         return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad4200067033854",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now we will make the UNET model with self attention layers :\n",
    "[]-> [][] ----------------------------------------------->O->[][] -> []- final output # 128\n",
    "        ->[][] ----------------------------->O->[][]->[]--^----^                      # 64\n",
    "              ->[][]-------------->O->[][]->[]^---^                                   # 32\n",
    "                    ------->16[][]-^--------^                                         # 16\n",
    "\n",
    "[]->ResConv\n",
    "O ->Self Attention\n",
    "image-> 128-64-32-16-32-64-128 -> new image\n",
    "\n",
    "num_block = 2+2+2+2+3+3 = 8+6 = 15 +- 1 vad eu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aea03a330a2506b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.in_ch = 3\n",
    "        self.out_ch = 64\n",
    "\n",
    "        self.conv_down_1 = DownConv(3, 64)\n",
    "        self.conv_down_2 = DownConv(64, 128)\n",
    "        self.conv_down_3 = DownConv(128, 256)\n",
    "\n",
    "        self.bottleneck = ResConv(256, 256)\n",
    "\n",
    "        self.conv_up_1 = UpConv(256, 128, 256)  # Corrected to match the number of output channels and batch_norm_features\n",
    "        self.att_1 = Attention(in_ch_skip=256)\n",
    "        \n",
    "        self.conv_up_2 = UpConv(128, 64, 128)  # Corrected to match the number of output channels and batch_norm_features\n",
    "        self.att_2 = Attention(in_ch_skip=128)\n",
    "\n",
    "        self.conv_up_3 = UpConv(64, 32,192)\n",
    "        self.att_3 = Attention(in_ch_skip=64)\n",
    "\n",
    "        self.out_proj = nn.Conv2d(32, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, x1 = self.conv_down_1(x)\n",
    "        x, x2 = self.conv_down_2(x)\n",
    "        x, x3 = self.conv_down_3(x)\n",
    "\n",
    "        x,_ = self.bottleneck(x)\n",
    "\n",
    "        x, _ = self.conv_up_1(x, x3)\n",
    "        x = self.att_1(x3, x)\n",
    "\n",
    "        x, _ = self.conv_up_2(x, x2)\n",
    "        x = self.att_2(x2, x)\n",
    "\n",
    "        x, _ = self.conv_up_3(x, x1)\n",
    "        x = self.att_3(x1, x)\n",
    "\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b08832c1d486d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "\n",
    "total_params = [param.numel() for param in model.parameters()]\n",
    "total_params = sum(total_params)\n",
    "total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c69e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_input = torch.randn(1, 3, 256, 256)  # Assuming input size of 256x256 and 3 channels\n",
    "model(sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305603aeaf739d7",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2276afd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf441846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea060d05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d0eb9b5067c505",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6236d7be27ffccb",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3540ec75358be0e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770b47ab83b7e403",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b729650eb60b4d7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a4b4238d42d479",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bdae2d4822d2ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa565a11319aad",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab843f0f291daf2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf30003205371202",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3be8dea6bd169e2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
